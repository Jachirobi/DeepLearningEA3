<!DOCTYPE html>
<html lang="de">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Language Model mit LSTM</title>
<link rel="stylesheet" href="style.css">
<script
	src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.13.0/dist/tf.min.js"></script>
<script
	src="https://cdnjs.cloudflare.com/ajax/libs/seedrandom/3.0.5/seedrandom.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
</head>
<body>

	<div class="container">
		<header>
			<div class="header-inhalt">
				<h1>Language Model mit LSTM</h1>
				<button id="darkModeToggle" aria-pressed="false"
					aria-label="Dark Mode umschalten"
					title="Hell-/Dunkelmodus umschalten">üåô Dark Mode
					aktivieren</button>
			</div>
		</header>

		<div class="allgemeine-informationen collapsible-section">
			<div class="section-header">
				<h2>Aufgabenstellung</h2>
				<button class="toggle-button" aria-expanded="true"
					aria-controls="aufgaben-section"
					title="Abschnitt ein- oder ausklappen">‚¨áÔ∏è Einklappen</button>
			</div>
			<div class="section-content" id="aufgaben-section">
				<p>Erstellen Sie ein Language Model (LM) zur Wortvorhersage.
					Trainieren Sie dazu ein Long Short-Term Memory (LSTM) Netzwerk auf
					der Basis der Daten (siehe den Punkt ‚ÄûDaten‚Äú unten) zur
					Wortvorhersage (Next Word Prediction). Mittels des trainierten LSTM
					Language-Models kann autoregressiv ein Text generiert werden, in
					dem das jeweils vorhergesagte Wort an den vorhandenen Text
					angeh√§ngt wird.</p>

				<h2>Modell und Optimierung</h2>
				<ul>
					<li>Stacked LSTM: 2 Hidden Layers (rekursiv) mit je 100 LSTM
						Units (andere Architekturen m√∂glich).</li>
					<li>Softmax Output mit der Dimension des Dictionaries.</li>
					<li>Loss-Funktion: Cross-Entropy.</li>
					<li>Optimizer: Adam mit Lernrate 0.01.</li>
					<li>Batch-Size: 32 (Variation erlaubt).</li>
					<li>Anzahl Trainings-Epochen: nach Beobachtung des Loss, z.‚ÄØB.
						mit Tensorflow Visor.</li>
				</ul>

				<h2>Interaktion</h2>
				<ul>
					<li><strong>I1)</strong> Der Nutzer kann einen Text (Prompt)
						eingeben. Dieser muss aus vollst√§ndigen, durch Leerzeichen
						getrennten W√∂rtern bestehen. Durch Klick auf den Button <em>‚ÄûVorhersage‚Äú</em>
						werden die wahrscheinlichsten folgenden W√∂rter mit
						Wahrscheinlichkeiten angezeigt. Der Nutzer kann eines dieser
						W√∂rter ausw√§hlen, welches dann angeh√§ngt wird. Danach startet
						automatisch eine neue Vorhersage.</li>
					<li><strong>I2)</strong> Mit dem Button <em>‚ÄûWeiter‚Äú</em> kann
						das wahrscheinlichste Wort automatisch angeh√§ngt werden. Danach
						startet erneut eine Vorhersage. Wiederholtes Klicken erzeugt einen
						fortlaufenden Text.</li>
					<li><strong>I3)</strong> √úber den Button <em>‚ÄûAuto‚Äú</em>
						k√∂nnen automatisch bis zu 10 W√∂rter vorhergesagt werden. Dieser
						Vorgang kann mit dem Button <em>‚ÄûStopp‚Äú</em> unterbrochen werden.</li>
					<li><strong>I4)</strong> Mit dem Button <em>‚ÄûReset‚Äú</em>
						werden sowohl der eingegebene Text als auch das Netzwerk
						zur√ºckgesetzt.</li>
				</ul>

				<h3>Buttons</h3>
				<ul>
					<li>Vorhersage</li>
					<li>Weiter</li>
					<li>Auto</li>
					<li>Stopp</li>
					<li>Wortauswahl (bei I1)</li>
				</ul>

				<h2>Experimente und Fragestellungen</h2>
				<ol>
					<li>Experimentieren Sie mit der Netzwerkarchitektur.
						Dokumentieren und begr√ºnden Sie Ihre finale Architektur.</li>
					<li>Notieren Sie, wie oft die Vorhersage exakt korrekt ist
						(k=1), und wie oft das korrekte n√§chste Wort unter den ersten k
						Vorhersagen liegt (k = 5, 10, 20, 100). Optional: Berechnung der
						Perplexity als zus√§tzliches Ma√ü.</li>
					<li>Untersuchen Sie, ob sich die urspr√ºnglichen Trainingsdaten
						mit dem trainierten Modell rekonstruieren lassen. Diskutieren Sie
						m√∂gliche Datenschutzprobleme.</li>
				</ol>
			</div>
		</div>

		<section class="interaktion-section">
			<h2>Interaktive Wortvorhersage</h2>

			<div class="interaktion-ui">
				<label for="userPrompt">Eingabetext:</label>
				<textarea id="userPrompt"
					placeholder="Geben Sie hier Ihren Text ein..."></textarea>

				<div class="button-row">
					<button id="predictBtn">üîÆ Vorhersage</button>
					<button id="weiterBtn">‚û°Ô∏è Weiter</button>
					<button id="autoBtn">ü§ñ Auto</button>
					<button id="stopBtn">üõë Stopp</button>
					<button id="resetBtn">üîÑ Reset</button>
				</div>
			</div>

			<div id="suggestionsContainer">
				<h3>Wortvorschl√§ge</h3>
				<ul id="suggestionsList">
					<!-- Dynamisch eingef√ºgte Vorschl√§ge -->
				</ul>
			</div>

			<div id="chartContainer">
				<h3>Modellbewertung</h3>
				<canvas id="accuracyChart" width="400" height="200"></canvas>
			</div>
		</section>


		<section class="experimente collapsible-section">
			<div class="section-header">
				<h2>Experimente und Fragestellungen</h2>
				<button class="toggle-button" aria-expanded="true"
					aria-controls="experimente-section"
					title="Abschnitt ein- oder ausklappen">‚¨áÔ∏è Einklappen</button>
			</div>
			<div class="section-content" id="experimente-section">
				<p>Zus√§tzlich zur Grundaufgabe wurden im Rahmen der Experimente
					verschiedene Aspekte des Lernverhaltens und der
					Generalisierungsf√§higkeit des Feedforward Neural Networks (FFNN)
					systematisch untersucht:</p>

				<h3>1) Einfluss der Modellarchitektur</h3>
				<p>Erh√∂ht man die Anzahl der Hidden-Layer von 1 oder 2 auf 3
					und/oder die Anzahl der Neuronen pro Layer, lernt das Modell
					schneller und kann die Trainingsdaten sehr gut bestimmen (Best-Fit
					tritt fr√ºher ein). Dabei zeigte sich, dass Overfitting in diesem
					Setup (glatte Ziel-Funktion, relativ viele Datenpunkte) nicht
					unmittelbar auftrat, sondern erst bei sehr hohen Epochenzahlen.
					Dies liegt unter anderem daran, dass ein gro√ües Netzwerk bei einer
					glatten Funktion zun√§chst eine l√§ngere "Underfitting"-Phase
					durchl√§uft und erst mit fortschreitendem Training beginnt, das
					vorhandene Rauschen in den Daten zu modellieren. Gerade bei st√§rker
					verrauschten Daten war dennoch beobachtbar, dass Overfitting fr√ºher
					und st√§rker auftrat, je gr√∂√üer die Architektur war.</p>

				<p>Die Wahl der Aktivierungsfunktion zeigte, dass ReLU gegen√ºber
					tanh eine stabilere Konvergenz und geringeres Overfitting-Verhalten
					aufwies.</p>

				<h3>2) Einfluss der Datenmenge</h3>
				<p>Bei einer Reduktion der Datenpunkte auf N = 50 (25 Train, 25
					Test) war eine starke √úberanpassung sichtbar; das Modell lernte die
					Trainingsdaten, konnte aber nicht mehr gut generalisieren,
					Overfitting trat fr√ºher auf. Bei Erh√∂hung auf N = 200 oder N = 500
					wurde das Modell deutlich robuster und generalisierte wesentlich
					besser. Overfitting trat sp√§ter oder gar nicht mehr auf.</p>

				<h3>3) Einfluss der Rauschst√§rke</h3>
				<p>Bei starker Rauschvarianz (V ‚â• 0.3) war es kaum noch m√∂glich,
					ein Modell zu trainieren, das die zugrunde liegende Funktion
					zuverl√§ssig abbildet. Bereits bei V = 0.1 zeigten sich leichte
					Einbu√üen in der Generalisierung. Bei sehr niedrigem Rauschen (V ‚â§
					0.01) entsprach das Verhalten weitgehend dem unverrauschten Fall.</p>

				<h3>4) Einfluss der Lernrate</h3>
				<p>Eine Lernrate von 0.01 erwies sich als gut geeignet. Bei
					0.001 war das Training sehr langsam. H√∂here Lernraten (‚â• 0.05)
					f√ºhrten oft zu instabilem Verhalten oder Divergenz. Zu kleine
					Lernraten brachten zudem die Gefahr von "zu fr√ºhem Overfitting", da
					das Modell zu langsam optimierte.</p>

				<h3>5) Dynamik des Overfittings</h3>
				<p>Die Beobachtung der Lernkurven (Train-Loss vs. Test-Loss)
					zeigte: Overfitting begann meist zwischen 500 und 15000 Epochen, je
					nach Rauschen und Architektur. Bei h√∂herer Modellkomplexit√§t und
					geringer Datenmenge trat Overfitting fr√ºher auf. Ein typisches
					Signal war das Auseinanderdriften der Loss-Kurven nach einer Phase
					synchronen Abfalls.</p>

				<h3>6) Stabilit√§t bei unterschiedlicher Initialisierung</h3>
				<p>Mehrere L√§ufe mit unterschiedlichen Startwerten zeigten, dass
					bei konstanter Architektur und Datenmenge die Resultate recht
					stabil blieben. Bei kleinen Datens√§tzen (N = 50) und hohem Rauschen
					waren die Schwankungen deutlich gr√∂√üer (z. B. Test-MSE von 0.1 bis
					0.3).</p>

				<h3>7) Generalisierung au√üerhalb des Trainingsbereichs</h3>
				<p>Ein Experiment mit x-Werten im Bereich [-3, +3] zeigte, dass
					das Modell erwartungsgem√§√ü nur im Trainingsbereich [-2, +2]
					zuverl√§ssig vorhersagen konnte. Au√üerhalb dieses Bereichs
					extrapolierte es stark unsicher und produzierte unrealistische
					Werte. Dies unterstreicht die Bedeutung einer geeigneten
					Datenabdeckung im Trainingsbereich.</p>

				<h3>Fazit</h3>
				<p>Die durchgef√ºhrten Experimente haben eindrucksvoll gezeigt,
					wie Modellarchitektur, Datenmenge, Rauschst√§rke und
					Optimierungsparameter das Lern- und Generalisierungsverhalten eines
					neuronalen Netzes beeinflussen. Besonders wichtig ist dabei das
					sorgf√§ltige Monitoring von Overfitting anhand der Test-Loss-Kurve.
					Die Nutzung von TensorFlow.js und die dynamische Visualisierung im
					Browser erwiesen sich als sehr hilfreiche Werkzeuge f√ºr diese
					Analyse.</p>
			</div>
		</section>


		<div class="diskussion collapsible-section">
			<div class="section-header">
				<h2>Diskussion</h2>
				<button class="toggle-button" aria-expanded="true"
					aria-controls="aufgaben-section"
					title="Abschnitt ein- oder ausklappen">‚¨áÔ∏è Einklappen</button>
			</div>
			<div class="section-content" id="aufgaben-section">
				<p>F√ºr die Regression der gegebenen Funktion wurde ein
					Feedforward Neural Network (FFNN) mit konfigurierbarer Architektur
					eingesetzt (2 Hidden-Layer, je 100 Neuronen, ReLU-Aktivierung,
					Adam-Optimizer mit Lernrate 0.01 und Batch-Size 32). Die Anzahl der
					Datenpunkte (N) und die Rauschvarianz (V) wurden gem√§√ü Vorgabe
					flexibel gestaltet (hier typischerweise N = 100, V = 0.05). Dadurch
					konnten gezielt Auswirkungen von Datenmenge und Rauschst√§rke auf
					das Modellverhalten untersucht werden.</p>
				<p>
					Auf den <strong>unverrauschten Daten</strong> zeigte das Modell bei
					einer Epochenzahl von 1000 ein sehr gutes Fit-Verhalten (Train- und
					Test-MSE < 0.0001). Bei den <strong>verrauschten Daten</strong>
					f√ºhrte ein Bereich von ca. 100-300 Epochen zu einer ausgewogenen
					Generalisierung (Train-MSE ~0.04-0.06, Test-MSE ~0.06-0.08). Bei
					sehr hoher Epochenanzahl (ab ca. 15.000) konnte Overfitting
					deutlich beobachtet werden: der Train-Loss sinkt weiter (&lt;0.02),
					w√§hrend der Test-Loss ansteigt (&gt;0.12 bei 15.000 und &gt;0.32
					bei 20.000).
				</p>
				<p>√Ñnderungen an der Architektur (z.B. zus√§tzliche Layer oder
					mehr Neuronen) zeigten, dass komplexere Modelle tendenziell
					schneller zu Overfitting neigen, insbesondere bei kleinen
					Datens√§tzen oder hoher Rauschvarianz. Ebenso wirkt sich die Wahl
					der Aktivierungsfunktion auf die Lernstabilit√§t aus (ReLU erwies
					sich hier als robust). Die Erh√∂hung der Datenpunkte f√ºhrte hingegen
					zu einem schnelleren Best-Fit Verhalten und einer Angleichung
					zwischen Test- und Trainings-MSE sowie einem viel sp√§teren
					Overt-Fit.</p>
				<p>Insgesamt hat dieses Experiment sehr anschaulich
					verdeutlicht, wie Modellkomplexit√§t, Trainingsdauer, Datenmenge und
					Rauschlevel gemeinsam das Lern- und Generalisierungsverhalten eines
					neuronalen Netzes bestimmen.</p>
			</div>
		</div>

		<main class="collapsible-section">
			<div class="section-header">
				<h2>Dokumentation</h2>
				<button class="toggle-button" aria-expanded="true"
					aria-controls="aufgaben-section"
					title="Abschnitt ein- oder ausklappen">‚¨áÔ∏è Einklappen</button>
			</div>
			<div class="section-content" id="aufgaben-section">
				<h3>1) Technisch</h3>
				<p>In der L√∂sung wurden folgende Frameworks und Libraries
					verwendet:</p>
				<ul>
					<li><strong>TensorFlow.js</strong>: zur Implementierung und
						Ausf√ºhrung des neuronalen Netzes (FFNN) direkt im Browser
						(Training, Evaluation und Inferenz).</li>
					<li><strong>Chart.js</strong>: zur Visualisierung der
						Lernkurven (Train- und Test-Loss √ºber Epochen).</li>
				</ul>
				<p>
					Technische Besonderheiten der L√∂sung: Das gesamte Training und die
					Modellberechnungen erfolgen vollst√§ndig clientseitig im Browser mit
					TensorFlow.js, ohne Server oder Backend. Die Lernkurve wird
					performant aufgebaut, indem der Train-Loss direkt aus
					<code>fit()</code>
					und der Test-Loss gezielt mit
					<code>evaluate()</code>
					ermittelt wird. Zus√§tzlich sind interaktive Steuerelemente (Slider
					und Dropdowns) integriert, um Datenparameter (N, Rauschvarianz) und
					Modellarchitektur (Layer, Neuronen, Aktivierungsfunktion) dynamisch
					anzupassen. Eine Fortschrittsanzeige informiert w√§hrend des
					Trainings √ºber den aktuellen Stand.
				</p>

				<h3>2) Fachlich</h3>
				<p>Die Logik der Implementierung orientiert sich an der
					Aufgabenstellung: Zun√§chst wird ein unverrauschter Datensatz
					generiert und f√ºr das Modelltraining genutzt. Anschlie√üend werden
					verrauschte Daten erzeugt und in zwei Varianten trainiert (Best-Fit
					und Overfit), um die Auswirkungen von Epochenzahl und
					Modellkomplexit√§t auf die Generalisierungsf√§higkeit zu untersuchen.
					F√ºr das Training wird der Adam-Optimizer mit Lernrate 0.01 und
					Batch-Size 32 eingesetzt. Die Modelle bestehen aus 1‚Äì3
					Hidden-Layern mit konfigurierbarer Neuronenzahl und
					ReLU-Aktivierung; der Output-Layer ist linear.</p>
				<p>Durch die einheitliche und kontrollierte Visualisierung der
					Lernkurven sowie der Modellvorhersagen konnten wichtige Effekte wie
					Overfitting und Bias-Variance-Verhalten beobachtet und
					nachvollzogen werden. Besonderer Wert wurde darauf gelegt, die
					Testdaten strikt nur zur Evaluation zu verwenden, um eine
					realistische Einsch√§tzung der Modellgeneraliserung zu
					gew√§hrleisten.</p>
				<p>Um den Nutzer Hilfestellungen zu geben, wurden an den
					wichtigsten Stellen Tooltips integriert. F√ºr die Barrierefreiheit
					wurde versucht alles zu ber√ºcksichtigen. Dazu geh√∂ren
					beispielsweise aria-label, alt-texte oder Kontraste bei der
					Farbauswahl.</p>
				<p>
					Quellen: TensorFlow.js Dokumentation (<a
						href="https://js.tensorflow.org" target="_blank">https://js.tensorflow.org</a>),
					Chart.js Dokumentation (<a href="https://www.chartjs.org"
						target="_blank">https://www.chartjs.org</a>), begleitende
					Vorlesungsfolien und √úbungsmaterialien.
				</p>
			</div>
		</main>
		<footer>Thomas Brehmer</footer>
	</div>

	<script src="script2.js"></script>
</body>
</html>
