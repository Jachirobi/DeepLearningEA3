<!DOCTYPE html>
<html lang="de">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Language Model mit LSTM</title>
<link rel="stylesheet" href="style.css">
<script
	src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.13.0/dist/tf.min.js"></script>
<script
	src="https://cdnjs.cloudflare.com/ajax/libs/seedrandom/3.0.5/seedrandom.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
</head>
<body>

	<div class="container">
		<header>
			<div class="header-inhalt">
				<h1>Language Model mit LSTM</h1>
				<button id="darkModeToggle" aria-pressed="false"
					aria-label="Dark Mode umschalten"
					title="Hell-/Dunkelmodus umschalten">🌙 Dark Mode
					aktivieren</button>
			</div>
		</header>

		<div class="allgemeine-informationen collapsible-section">
			<div class="section-header">
				<h2>Aufgabenstellung</h2>
				<button class="toggle-button" aria-expanded="true"
					aria-controls="aufgaben-section"
					title="Abschnitt ein- oder ausklappen">⬇️ Einklappen</button>
			</div>
			<div class="section-content" id="aufgaben-section">
				<p>Erstellen Sie ein Language Model (LM) zur Wortvorhersage.
					Trainieren Sie dazu ein Long Short-Term Memory (LSTM) Netzwerk auf
					der Basis der Daten (siehe den Punkt „Daten“ unten) zur
					Wortvorhersage (Next Word Prediction). Mittels des trainierten LSTM
					Language-Models kann autoregressiv ein Text generiert werden, in
					dem das jeweils vorhergesagte Wort an den vorhandenen Text
					angehängt wird.</p>

				<h2>Modell und Optimierung</h2>
				<ul>
					<li>Stacked LSTM: 2 Hidden Layers (rekursiv) mit je 100 LSTM
						Units (andere Architekturen möglich).</li>
					<li>Softmax Output mit der Dimension des Dictionaries.</li>
					<li>Loss-Funktion: Cross-Entropy.</li>
					<li>Optimizer: Adam mit Lernrate 0.01.</li>
					<li>Batch-Size: 32 (Variation erlaubt).</li>
					<li>Anzahl Trainings-Epochen: nach Beobachtung des Loss, z. B.
						mit Tensorflow Visor.</li>
				</ul>

				<h2>Interaktion</h2>
				<ul>
					<li><strong>I1)</strong> Der Nutzer kann einen Text (Prompt)
						eingeben. Dieser muss aus vollständigen, durch Leerzeichen
						getrennten Wörtern bestehen. Durch Klick auf den Button <em>„Vorhersage“</em>
						werden die wahrscheinlichsten folgenden Wörter mit
						Wahrscheinlichkeiten angezeigt. Der Nutzer kann eines dieser
						Wörter auswählen, welches dann angehängt wird. Danach startet
						automatisch eine neue Vorhersage.</li>
					<li><strong>I2)</strong> Mit dem Button <em>„Weiter“</em> kann
						das wahrscheinlichste Wort automatisch angehängt werden. Danach
						startet erneut eine Vorhersage. Wiederholtes Klicken erzeugt einen
						fortlaufenden Text.</li>
					<li><strong>I3)</strong> Über den Button <em>„Auto“</em>
						können automatisch bis zu 10 Wörter vorhergesagt werden. Dieser
						Vorgang kann mit dem Button <em>„Stopp“</em> unterbrochen werden.</li>
					<li><strong>I4)</strong> Mit dem Button <em>„Reset“</em>
						werden sowohl der eingegebene Text als auch das Netzwerk
						zurückgesetzt.</li>
				</ul>

				<h3>Buttons</h3>
				<ul>
					<li>Vorhersage</li>
					<li>Weiter</li>
					<li>Auto</li>
					<li>Stopp</li>
					<li>Wortauswahl (bei I1)</li>
				</ul>

				<h2>Experimente und Fragestellungen</h2>
				<ol>
					<li>Experimentieren Sie mit der Netzwerkarchitektur.
						Dokumentieren und begründen Sie Ihre finale Architektur.</li>
					<li>Notieren Sie, wie oft die Vorhersage exakt korrekt ist
						(k=1), und wie oft das korrekte nächste Wort unter den ersten k
						Vorhersagen liegt (k = 5, 10, 20, 100). Optional: Berechnung der
						Perplexity als zusätzliches Maß.</li>
					<li>Untersuchen Sie, ob sich die ursprünglichen Trainingsdaten
						mit dem trainierten Modell rekonstruieren lassen. Diskutieren Sie
						mögliche Datenschutzprobleme.</li>
				</ol>
			</div>
		</div>

		<section class="interaktion-section">
			<h2>Interaktive Wortvorhersage</h2>

			<div class="interaktion-ui">
				<label for="userPrompt">Eingabetext:</label>
				<textarea id="userPrompt"
					placeholder="Geben Sie hier Ihren Text ein..."></textarea>

				<div class="button-row">
					<button id="predictBtn">🔮 Vorhersage</button>
					<button id="weiterBtn">➡️ Weiter</button>
					<button id="autoBtn">🤖 Auto</button>
					<button id="stopBtn">🛑 Stopp</button>
					<button id="resetBtn">🔄 Reset</button>
				</div>
			</div>

			<div id="suggestionsContainer">
				<h3>Wortvorschläge</h3>
				<ul id="suggestionsList">
					<!-- Dynamisch eingefügte Vorschläge -->
				</ul>
			</div>

			<div id="chartContainer">
				<h3>Modellbewertung</h3>
				<canvas id="accuracyChart" width="400" height="200"></canvas>
			</div>
		</section>


		<section class="experimente collapsible-section">
			<div class="section-header">
				<h2>Experimente und Fragestellungen</h2>
				<button class="toggle-button" aria-expanded="true"
					aria-controls="experimente-section"
					title="Abschnitt ein- oder ausklappen">⬇️ Einklappen</button>
			</div>
			<div class="section-content" id="experimente-section">
				<p>Zusätzlich zur Grundaufgabe wurden im Rahmen der Experimente
					verschiedene Aspekte des Lernverhaltens und der
					Generalisierungsfähigkeit des Feedforward Neural Networks (FFNN)
					systematisch untersucht:</p>

				<h3>1) Einfluss der Modellarchitektur</h3>
				<p>Erhöht man die Anzahl der Hidden-Layer von 1 oder 2 auf 3
					und/oder die Anzahl der Neuronen pro Layer, lernt das Modell
					schneller und kann die Trainingsdaten sehr gut bestimmen (Best-Fit
					tritt früher ein). Dabei zeigte sich, dass Overfitting in diesem
					Setup (glatte Ziel-Funktion, relativ viele Datenpunkte) nicht
					unmittelbar auftrat, sondern erst bei sehr hohen Epochenzahlen.
					Dies liegt unter anderem daran, dass ein großes Netzwerk bei einer
					glatten Funktion zunächst eine längere "Underfitting"-Phase
					durchläuft und erst mit fortschreitendem Training beginnt, das
					vorhandene Rauschen in den Daten zu modellieren. Gerade bei stärker
					verrauschten Daten war dennoch beobachtbar, dass Overfitting früher
					und stärker auftrat, je größer die Architektur war.</p>

				<p>Die Wahl der Aktivierungsfunktion zeigte, dass ReLU gegenüber
					tanh eine stabilere Konvergenz und geringeres Overfitting-Verhalten
					aufwies.</p>

				<h3>2) Einfluss der Datenmenge</h3>
				<p>Bei einer Reduktion der Datenpunkte auf N = 50 (25 Train, 25
					Test) war eine starke Überanpassung sichtbar; das Modell lernte die
					Trainingsdaten, konnte aber nicht mehr gut generalisieren,
					Overfitting trat früher auf. Bei Erhöhung auf N = 200 oder N = 500
					wurde das Modell deutlich robuster und generalisierte wesentlich
					besser. Overfitting trat später oder gar nicht mehr auf.</p>

				<h3>3) Einfluss der Rauschstärke</h3>
				<p>Bei starker Rauschvarianz (V ≥ 0.3) war es kaum noch möglich,
					ein Modell zu trainieren, das die zugrunde liegende Funktion
					zuverlässig abbildet. Bereits bei V = 0.1 zeigten sich leichte
					Einbußen in der Generalisierung. Bei sehr niedrigem Rauschen (V ≤
					0.01) entsprach das Verhalten weitgehend dem unverrauschten Fall.</p>

				<h3>4) Einfluss der Lernrate</h3>
				<p>Eine Lernrate von 0.01 erwies sich als gut geeignet. Bei
					0.001 war das Training sehr langsam. Höhere Lernraten (≥ 0.05)
					führten oft zu instabilem Verhalten oder Divergenz. Zu kleine
					Lernraten brachten zudem die Gefahr von "zu frühem Overfitting", da
					das Modell zu langsam optimierte.</p>

				<h3>5) Dynamik des Overfittings</h3>
				<p>Die Beobachtung der Lernkurven (Train-Loss vs. Test-Loss)
					zeigte: Overfitting begann meist zwischen 500 und 15000 Epochen, je
					nach Rauschen und Architektur. Bei höherer Modellkomplexität und
					geringer Datenmenge trat Overfitting früher auf. Ein typisches
					Signal war das Auseinanderdriften der Loss-Kurven nach einer Phase
					synchronen Abfalls.</p>

				<h3>6) Stabilität bei unterschiedlicher Initialisierung</h3>
				<p>Mehrere Läufe mit unterschiedlichen Startwerten zeigten, dass
					bei konstanter Architektur und Datenmenge die Resultate recht
					stabil blieben. Bei kleinen Datensätzen (N = 50) und hohem Rauschen
					waren die Schwankungen deutlich größer (z. B. Test-MSE von 0.1 bis
					0.3).</p>

				<h3>7) Generalisierung außerhalb des Trainingsbereichs</h3>
				<p>Ein Experiment mit x-Werten im Bereich [-3, +3] zeigte, dass
					das Modell erwartungsgemäß nur im Trainingsbereich [-2, +2]
					zuverlässig vorhersagen konnte. Außerhalb dieses Bereichs
					extrapolierte es stark unsicher und produzierte unrealistische
					Werte. Dies unterstreicht die Bedeutung einer geeigneten
					Datenabdeckung im Trainingsbereich.</p>

				<h3>Fazit</h3>
				<p>Die durchgeführten Experimente haben eindrucksvoll gezeigt,
					wie Modellarchitektur, Datenmenge, Rauschstärke und
					Optimierungsparameter das Lern- und Generalisierungsverhalten eines
					neuronalen Netzes beeinflussen. Besonders wichtig ist dabei das
					sorgfältige Monitoring von Overfitting anhand der Test-Loss-Kurve.
					Die Nutzung von TensorFlow.js und die dynamische Visualisierung im
					Browser erwiesen sich als sehr hilfreiche Werkzeuge für diese
					Analyse.</p>
			</div>
		</section>


		<div class="diskussion collapsible-section">
			<div class="section-header">
				<h2>Diskussion</h2>
				<button class="toggle-button" aria-expanded="true"
					aria-controls="aufgaben-section"
					title="Abschnitt ein- oder ausklappen">⬇️ Einklappen</button>
			</div>
			<div class="section-content" id="aufgaben-section">
				<p>Für die Regression der gegebenen Funktion wurde ein
					Feedforward Neural Network (FFNN) mit konfigurierbarer Architektur
					eingesetzt (2 Hidden-Layer, je 100 Neuronen, ReLU-Aktivierung,
					Adam-Optimizer mit Lernrate 0.01 und Batch-Size 32). Die Anzahl der
					Datenpunkte (N) und die Rauschvarianz (V) wurden gemäß Vorgabe
					flexibel gestaltet (hier typischerweise N = 100, V = 0.05). Dadurch
					konnten gezielt Auswirkungen von Datenmenge und Rauschstärke auf
					das Modellverhalten untersucht werden.</p>
				<p>
					Auf den <strong>unverrauschten Daten</strong> zeigte das Modell bei
					einer Epochenzahl von 1000 ein sehr gutes Fit-Verhalten (Train- und
					Test-MSE < 0.0001). Bei den <strong>verrauschten Daten</strong>
					führte ein Bereich von ca. 100-300 Epochen zu einer ausgewogenen
					Generalisierung (Train-MSE ~0.04-0.06, Test-MSE ~0.06-0.08). Bei
					sehr hoher Epochenanzahl (ab ca. 15.000) konnte Overfitting
					deutlich beobachtet werden: der Train-Loss sinkt weiter (&lt;0.02),
					während der Test-Loss ansteigt (&gt;0.12 bei 15.000 und &gt;0.32
					bei 20.000).
				</p>
				<p>Änderungen an der Architektur (z.B. zusätzliche Layer oder
					mehr Neuronen) zeigten, dass komplexere Modelle tendenziell
					schneller zu Overfitting neigen, insbesondere bei kleinen
					Datensätzen oder hoher Rauschvarianz. Ebenso wirkt sich die Wahl
					der Aktivierungsfunktion auf die Lernstabilität aus (ReLU erwies
					sich hier als robust). Die Erhöhung der Datenpunkte führte hingegen
					zu einem schnelleren Best-Fit Verhalten und einer Angleichung
					zwischen Test- und Trainings-MSE sowie einem viel späteren
					Overt-Fit.</p>
				<p>Insgesamt hat dieses Experiment sehr anschaulich
					verdeutlicht, wie Modellkomplexität, Trainingsdauer, Datenmenge und
					Rauschlevel gemeinsam das Lern- und Generalisierungsverhalten eines
					neuronalen Netzes bestimmen.</p>
			</div>
		</div>

		<main class="collapsible-section">
			<div class="section-header">
				<h2>Dokumentation</h2>
				<button class="toggle-button" aria-expanded="true"
					aria-controls="aufgaben-section"
					title="Abschnitt ein- oder ausklappen">⬇️ Einklappen</button>
			</div>
			<div class="section-content" id="aufgaben-section">
				<h3>1) Technisch</h3>
				<p>In der Lösung wurden folgende Frameworks und Libraries
					verwendet:</p>
				<ul>
					<li><strong>TensorFlow.js</strong>: zur Implementierung und
						Ausführung des neuronalen Netzes (FFNN) direkt im Browser
						(Training, Evaluation und Inferenz).</li>
					<li><strong>Chart.js</strong>: zur Visualisierung der
						Lernkurven (Train- und Test-Loss über Epochen).</li>
				</ul>
				<p>
					Technische Besonderheiten der Lösung: Das gesamte Training und die
					Modellberechnungen erfolgen vollständig clientseitig im Browser mit
					TensorFlow.js, ohne Server oder Backend. Die Lernkurve wird
					performant aufgebaut, indem der Train-Loss direkt aus
					<code>fit()</code>
					und der Test-Loss gezielt mit
					<code>evaluate()</code>
					ermittelt wird. Zusätzlich sind interaktive Steuerelemente (Slider
					und Dropdowns) integriert, um Datenparameter (N, Rauschvarianz) und
					Modellarchitektur (Layer, Neuronen, Aktivierungsfunktion) dynamisch
					anzupassen. Eine Fortschrittsanzeige informiert während des
					Trainings über den aktuellen Stand.
				</p>

				<h3>2) Fachlich</h3>
				<p>Die Logik der Implementierung orientiert sich an der
					Aufgabenstellung: Zunächst wird ein unverrauschter Datensatz
					generiert und für das Modelltraining genutzt. Anschließend werden
					verrauschte Daten erzeugt und in zwei Varianten trainiert (Best-Fit
					und Overfit), um die Auswirkungen von Epochenzahl und
					Modellkomplexität auf die Generalisierungsfähigkeit zu untersuchen.
					Für das Training wird der Adam-Optimizer mit Lernrate 0.01 und
					Batch-Size 32 eingesetzt. Die Modelle bestehen aus 1–3
					Hidden-Layern mit konfigurierbarer Neuronenzahl und
					ReLU-Aktivierung; der Output-Layer ist linear.</p>
				<p>Durch die einheitliche und kontrollierte Visualisierung der
					Lernkurven sowie der Modellvorhersagen konnten wichtige Effekte wie
					Overfitting und Bias-Variance-Verhalten beobachtet und
					nachvollzogen werden. Besonderer Wert wurde darauf gelegt, die
					Testdaten strikt nur zur Evaluation zu verwenden, um eine
					realistische Einschätzung der Modellgeneraliserung zu
					gewährleisten.</p>
				<p>Um den Nutzer Hilfestellungen zu geben, wurden an den
					wichtigsten Stellen Tooltips integriert. Für die Barrierefreiheit
					wurde versucht alles zu berücksichtigen. Dazu gehören
					beispielsweise aria-label, alt-texte oder Kontraste bei der
					Farbauswahl.</p>
				<p>
					Quellen: TensorFlow.js Dokumentation (<a
						href="https://js.tensorflow.org" target="_blank">https://js.tensorflow.org</a>),
					Chart.js Dokumentation (<a href="https://www.chartjs.org"
						target="_blank">https://www.chartjs.org</a>), begleitende
					Vorlesungsfolien und Übungsmaterialien.
				</p>
			</div>
		</main>
		<footer>Thomas Brehmer</footer>
	</div>

	<script src="script2.js"></script>
</body>
</html>
